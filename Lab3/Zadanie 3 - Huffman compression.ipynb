{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression with Huffman Trees\n",
    "## Paweł Kruczkiewicz\n",
    "#### 31.03.2021 r.\n",
    "\n",
    "### Treść\n",
    "Zadanie polega na implementacji dwóch algorytmów kompresji:\n",
    "\n",
    "1. statycznego algorytmu Huffmana (1 punkt)\n",
    "2. dynamicznego algorytmu Huffmana (2 punkty)\n",
    "\n",
    "Dla każdego z algorytmów należy wykonać następujące zadania:\n",
    "\n",
    "1. Opracować format pliku przechowującego dane.\n",
    "2. Zaimplementować algorytm kompresji i dekompresji danych dla tego formatu pliku.\n",
    "3. Zmierzyć współczynnik kompresji (wyrażone w procentach: 1 - plik_skompresowany / plik_nieskompresowany) dla plików tekstowych o rozmiarach: 1kB, 10kB, 100kB, 1MB, dla różnych typów plików: plik tekstowy z portalu Guttenberga, plik źródłowy z Githubu, plik ze znakami losowanymi z rozkładu jednostajnego.\n",
    "4. Zmierzyć czas kompresji i dekompresji dla plików z punktu 3 dla każdego algorytmu.\n",
    "\n",
    "Zadanie dla chętnych:\n",
    "Zaimplementować dowolny algorytm ze zmiennym blokiem kompresji, który uzyska lepszy współczynnik kompresji na większości danych wejściowych, niż algorytmy Huffmana  (+2 punkty)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementacje\n",
    "### Kod Huffmana statyczny\n",
    "**Tworzenie drzewa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitarray import bitarray\n",
    "from bitarray.util import ba2int\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from math import inf\n",
    "\n",
    "\n",
    "class InternalNode:   \n",
    "    def __init__(self, left, right, weight, parent=None, index=None):\n",
    "        self.weight = weight\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.parent = parent  # only for addaptive huffman tree\n",
    "        self.index = index\n",
    "\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, letter, weight, parent=None, index=None):\n",
    "        self.weight = weight\n",
    "        self.letter = letter\n",
    "        self.parent = parent  # only for addaptive huffman tree\n",
    "        self.index = index\n",
    "\n",
    "\n",
    "def count_weights(text):   # counting number of occurences of a given character\n",
    "    result = dict()\n",
    "    for character in text:\n",
    "        val = result.get(character, 0)\n",
    "        result[character] = val + 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def smallest_two_elems(deq1, deq2):\n",
    "    result = []\n",
    "    while len(result) < 2:\n",
    "        smallest1 = Leaf(\"_\", inf)\n",
    "        smallest2 = Leaf(\"_\", inf)\n",
    "        if len(deq1):\n",
    "            smallest1 = deq1[0]\n",
    "        if len(deq2):\n",
    "            smallest2 = deq2[0]\n",
    "\n",
    "        if smallest1.weight < smallest2.weight:\n",
    "            result.append(deq1.popleft())\n",
    "        else:\n",
    "            result.append(deq2.popleft())\n",
    "\n",
    "    return tuple(result)\n",
    "\n",
    "\n",
    "def static_huffman(letter_count):   # gives the Huffman tree for a given text\n",
    "    n = len(letter_count)\n",
    "\n",
    "    leaves = [Leaf(sign, weight) for sign, weight in letter_count.items()]\n",
    "    leaves.sort(key=lambda x: x.weight)\n",
    "    leaves = deque(leaves)  # making deque of leaves\n",
    "\n",
    "    internal_nodes = deque()  # making empty deque for internal nodes\n",
    "\n",
    "    for _ in range(n - 1):\n",
    "        elem1, elem2 = smallest_two_elems(leaves, internal_nodes)\n",
    "        internal_nodes.append(InternalNode(elem1, elem2, elem1.weight + elem2.weight))\n",
    "\n",
    "    return internal_nodes[-1]  # == root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kodowanie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding format: \n",
    "    # 32 bits for number of characters = n,\n",
    "    # n times 8*(N_BYTES+K_BYTES) bits for character+its frequency\n",
    "    # encoded text\n",
    "\n",
    "    \n",
    "# we can customise how much data is needed for metadata (this values are minimum for tests included below)\n",
    "N_BYTES = 2  # no |of bits for number of characters\n",
    "K_BYTES = 3  # no of bits for frequency\n",
    "    \n",
    "    \n",
    "def is_instance(obj, class_name):\n",
    "    return obj.__class__.__name__ == class_name\n",
    "\n",
    "\n",
    "def give_dict(node, result=None, acc=\"\"):   #gives a mapping of characters to code\n",
    "    if is_instance(node, \"Leaf\"):\n",
    "        result[node.letter] = acc\n",
    "\n",
    "    if is_instance(node, \"InternalNode\"):\n",
    "        if result is None:  result = dict()  # empty result dict declaration\n",
    "\n",
    "        give_dict(node.left, result, acc + \"0\")\n",
    "        give_dict(node.right, result, acc + \"1\")\n",
    "        return result\n",
    "\n",
    "\n",
    "def encode_prefix(letters_count):  # encoding only the meta information \n",
    "    result = bitarray()\n",
    "\n",
    "    dict_len_bytes = len(letters_count).to_bytes(length=N_BYTES, byteorder='big', signed=False)\n",
    "    result.frombytes(dict_len_bytes)  # appending the length\n",
    "\n",
    "    for key, val in letters_count.items():\n",
    "        result.frombytes(ord(key).to_bytes(length=N_BYTES, byteorder='big', signed=False))  # encoding_key\n",
    "        result.frombytes(val.to_bytes(length=K_BYTES, byteorder='big', signed=False))  # encoding length of code\n",
    "\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def encode(text):\n",
    "    weight_dict = count_weights(text)\n",
    "    huff_tree_root = static_huffman(weight_dict)\n",
    "    code_dict = give_dict(huff_tree_root)\n",
    "\n",
    "    metadata = encode_prefix(weight_dict)\n",
    "    encoded_text = \"\".join([code_dict[letter] for letter in text])\n",
    "    return metadata + bitarray(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitarray('00000000000001010000000001100001000000000000000000000101000000000110001000000000000000000000001000000000011100100000000000000000000000100000000001100011000000000000000000000001000000000110010000000000000000000000000101111001100011010111100')\n"
     ]
    }
   ],
   "source": [
    "example = encode(\"abracadabra\")\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dekodowanie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(code):\n",
    "    def split_bitarray():   # here we: 1. decode all informations from metadata; 2. return the encoded text solely \n",
    "        n_bit = code[:8*N_BYTES]\n",
    "        n = ba2int(n_bit)\n",
    "        encoded_text_pointer = 8*N_BYTES + 8*n*(N_BYTES+K_BYTES)  # index of the first bit of the encoded text\n",
    "\n",
    "        char_count = dict()\n",
    "        for i in range(8*N_BYTES, encoded_text_pointer, 8*(N_BYTES + K_BYTES)):\n",
    "            character = chr(ba2int(code[i:i+8*N_BYTES], signed=False) )\n",
    "            i += 8*N_BYTES\n",
    "            count = ba2int(code[i:i+8*K_BYTES], signed=False)\n",
    "            char_count[character] = count\n",
    "\n",
    "        encoded_text = code[encoded_text_pointer:]\n",
    "        return n, char_count, encoded_text\n",
    "\n",
    "    def decode_text():  # the procedure of decoding code\n",
    "        result = ''\n",
    "        curr_node = huff_tree_root\n",
    "        for bit in encoded_text:\n",
    "            if is_instance(curr_node, \"InternalNode\"):\n",
    "                if bit == 0:\n",
    "                    curr_node = curr_node.left\n",
    "                else:\n",
    "                    curr_node = curr_node.right\n",
    "                if is_instance(curr_node, \"Leaf\"):\n",
    "                    result += curr_node.letter\n",
    "                    curr_node = huff_tree_root\n",
    "\n",
    "        return result\n",
    "\n",
    "    n, char_count, encoded_text = split_bitarray()\n",
    "    huff_tree_root = static_huffman(char_count)\n",
    "    return decode_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abracadabra'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kod Huffmana dynamiczny\n",
    "**funkcje pomocnicze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_code(curr_node):  # we go up the tree till we get parent\n",
    "    result = bitarray()\n",
    "    while curr_node is not None:\n",
    "        dad = curr_node.parent\n",
    "        if dad is not None and dad.left is curr_node:\n",
    "            result.append(False)\n",
    "        elif dad is not None and dad.right is curr_node:\n",
    "            result.append(True)\n",
    "        curr_node = dad\n",
    "\n",
    "    return result[::-1]  # reversing since we go up the tree (normally we go down)\n",
    "\n",
    "\n",
    "def update_indexes(root):\n",
    "    queue = Queue()\n",
    "    queue.put(root)\n",
    "    i = 0\n",
    "\n",
    "    while not queue.empty():\n",
    "        curr_node = queue.get()\n",
    "        curr_node.index = i\n",
    "        if is_instance(curr_node, \"InternalNode\"):\n",
    "            queue.put(curr_node.right)\n",
    "            queue.put(curr_node.left)\n",
    "        i += 1\n",
    "\n",
    "def increment(curr_node, nodes):  # go up the huffman tree, increment every node and swap if necessary\n",
    "    def swap_condition(curr, weight_leader):\n",
    "        return curr.parent is not None and weight_leader. parent is not None and \\\n",
    "               curr is not weight_leader.parent and curr.parent is not weight_leader\n",
    "\n",
    "    def swap(node_a, node_b):\n",
    "        if node_a.parent is node_b.parent:\n",
    "            if node_a.parent.left is node_a:\n",
    "                node_a.parent.left = node_b\n",
    "                node_a.parent.right = node_a\n",
    "            else:\n",
    "                node_a.parent.left = node_a\n",
    "                node_a.parent.right = node_b\n",
    "            return\n",
    "        node_a_parent = node_a.parent\n",
    "        node_b_parent = node_b.parent\n",
    "        if node_a is node_a_parent.left:\n",
    "            node_a_parent.left = node_b\n",
    "        else:\n",
    "            node_a_parent.right = node_b\n",
    "        if node_b is node_b_parent.left:\n",
    "            node_b_parent.left = node_a\n",
    "        else:\n",
    "            node_b_parent.right = node_a\n",
    "        node_a.parent = node_b_parent\n",
    "        node_b.parent = node_a_parent\n",
    "        node_a.index, node_b.index = node_b.index, node_a.index\n",
    "\n",
    "    while curr_node.parent is not None:\n",
    "        leaders = nodes[curr_node.weight]\n",
    "        leaders.sort(key=lambda x: x.index)\n",
    "        i = 0\n",
    "        while i < len(leaders) and leaders[i].index < curr_node.index:\n",
    "            leader = leaders[i]\n",
    "            if swap_condition(curr_node, leader):\n",
    "                swap(curr_node, leader)\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        add_weight_and_update_nodes(nodes, curr_node)\n",
    "        curr_node = curr_node.parent\n",
    "\n",
    "    add_weight_and_update_nodes(nodes, curr_node)\n",
    "    update_indexes(curr_node)\n",
    "\n",
    "\n",
    "def add_weight_and_update_nodes(nodes, curr_node):\n",
    "    old_weight_buddies = nodes[curr_node.weight]\n",
    "    if curr_node in old_weight_buddies:\n",
    "        old_weight_buddies.remove(curr_node)\n",
    "\n",
    "    curr_node.weight += 1\n",
    "\n",
    "    list_with_nodes_with_the_same_weight = nodes.setdefault(curr_node.weight, [])\n",
    "    list_with_nodes_with_the_same_weight.append(curr_node)\n",
    "\n",
    "\n",
    "def copy_leaf(leaf_node):  # make new InternalNode out of a given Leaf\n",
    "    new_node = InternalNode(None, None, leaf_node.weight, parent=leaf_node.parent)\n",
    "    if leaf_node.parent is not None:\n",
    "        if leaf_node.parent.left is leaf_node:\n",
    "            new_node.parent.left = new_node\n",
    "        else:\n",
    "            new_node.parent.right = new_node\n",
    "\n",
    "    return new_node\n",
    "\n",
    "\n",
    "def add_new_letter(zero_node, letter, leaves, nodes, root):  # making and rearranging the tree\n",
    "    new_internal = copy_leaf(zero_node)  # making internal node out of the zero node and attaching it to parent\n",
    "\n",
    "    new_leaf = Leaf(letter, 0, parent=new_internal)\n",
    "    add_weight_and_update_nodes(nodes, new_leaf)\n",
    "    new_internal.right = new_leaf\n",
    "    leaves[letter] = new_leaf\n",
    "\n",
    "    new_internal.left = zero_node\n",
    "    zero_node.parent = new_internal\n",
    "\n",
    "    if new_internal.parent is None:\n",
    "        root = new_internal\n",
    "\n",
    "    update_indexes(root)\n",
    "    increment(new_internal, nodes)\n",
    "    return new_internal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kodowanie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nyt means \"not yet transmitted\" - it's the \"zero\" node\n",
    "def adaptive_huffman_encode(text):\n",
    "    nyt_char = '\\uE000'  # special character in UNICODE\n",
    "    leaves = {nyt_char: Leaf(nyt_char, 0, parent=None, index=0)}\n",
    "    encoded_text = bitarray()\n",
    "    root = leaves[nyt_char]\n",
    "\n",
    "    nodes = {0: [root]}\n",
    "\n",
    "    for letter in text:\n",
    "        if letter in leaves:\n",
    "            curr_node = leaves[letter]\n",
    "            node_code = get_node_code(curr_node)\n",
    "            encoded_text += node_code\n",
    "\n",
    "            increment(curr_node, nodes)\n",
    "        else:\n",
    "            zero_node = leaves[nyt_char]\n",
    "\n",
    "            zero_node_code = get_node_code(zero_node)\n",
    "            encoded_text += zero_node_code\n",
    "            letter_bytes = ord(letter).to_bytes(length=N_BYTES, byteorder='big', signed=False)\n",
    "            encoded_text.frombytes(letter_bytes)\n",
    "\n",
    "            new_internal = add_new_letter(zero_node, letter, leaves, nodes, root)\n",
    "            if new_internal.parent is None:  # new_internal is the factual root\n",
    "                root = new_internal  # so we need to change it\n",
    "\n",
    "    return encoded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitarray('0000000001100001000000000011000100000000000011100100100000000000110001101100000000000110010001101100')\n"
     ]
    }
   ],
   "source": [
    "encoded_text = adaptive_huffman_encode('abracadabra')\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dekodowanie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_huffman_decode(code):\n",
    "    nyt_char = '\\uE000'  # special character in UNICODE\n",
    "    leaves = {nyt_char: Leaf(nyt_char, 0, parent=None)}\n",
    "    decoded_text = \"\"\n",
    "    root = leaves[nyt_char]\n",
    "\n",
    "    nodes = {0: [root]}\n",
    "    i = 0\n",
    "    while i < len(code):\n",
    "        curr_node = root\n",
    "        while is_instance(curr_node, \"InternalNode\"):\n",
    "            bit = code[i]\n",
    "            if bit == 0:\n",
    "                curr_node = curr_node.left\n",
    "            else:\n",
    "                curr_node = curr_node.right\n",
    "            i += 1\n",
    "\n",
    "        if curr_node.letter != nyt_char:  # the letter was previously in text\n",
    "            letter = curr_node.letter\n",
    "            decoded_text += letter\n",
    "            increment(curr_node, nodes)\n",
    "        else:                             # the first encounter of the letter (curr_node is zero_node)\n",
    "            letter = chr(ba2int(code[i:i + 8 * N_BYTES], signed=False))\n",
    "            i += 8 * N_BYTES\n",
    "            decoded_text += letter\n",
    "\n",
    "            zero_node = leaves[nyt_char]\n",
    "\n",
    "            new_internal = add_new_letter(zero_node, letter, leaves, nodes, root)\n",
    "            if new_internal.parent is None:  # new_internal is the factual root\n",
    "                root = new_internal  # so we need to change it\n",
    "\n",
    "    return decoded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abracadabra\n"
     ]
    }
   ],
   "source": [
    "decoded_text = adaptive_huffman_decode(encoded_text)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testy\n",
    "W folderze `testy` znajduja się pliki z tekstem do zakodowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "\n",
    "\n",
    "def test(tests_dir_name):\n",
    "    def unit_test(path, encode_function, decode_function, name):\n",
    "        with open(file_path, \"r\", encoding=\"utf8\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "        start_encode = time()\n",
    "        code = encode_function(text)\n",
    "        end_encode = time()\n",
    "\n",
    "        start_decode = time()\n",
    "        decode_function(code)\n",
    "        end_decode = time()\n",
    "\n",
    "        result_path = os.path.splitext(path)[0] + \"_result.txt\"\n",
    "        with open(result_path, \"wb\") as file:\n",
    "            code.tofile(file)\n",
    "\n",
    "        compressed_size = os.path.getsize(result_path)\n",
    "        uncompressed_size = os.path.getsize(path)\n",
    "\n",
    "        print(f'{name}')\n",
    "        print(f'{file_path}:')\n",
    "        print(f'encoding:  {round(end_encode - start_encode, 4)} [s]')\n",
    "        print(f'decoding:  {round(end_decode - start_decode, 4)} [s]')\n",
    "        print(f'compresion rate: {100 - 100*compressed_size/uncompressed_size} %')\n",
    "        print()\n",
    "        \n",
    "        os.remove(result_path)   # clean up after ourselves\n",
    "\n",
    "\n",
    "    curr_dir = os.getcwd()\n",
    "    os.chdir(tests_dir_name)\n",
    "    test_files_list = os.listdir(\".\")\n",
    "    try:\n",
    "        for file_path in sorted(test_files_list, key=os.path.getsize):\n",
    "            unit_test(file_path, encode, decode, \"static huffman\")   \n",
    "            unit_test(file_path, adaptive_huffman_encode, adaptive_huffman_decode, \"adaptive huffman\")\n",
    "    finally:\n",
    "        os.chdir(curr_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static huffman\n",
      "linux_1KB.txt:\n",
      "encoding:  0.0007 [s]\n",
      "decoding:  0.0025 [s]\n",
      "compresion rate: -1.001251564455572 %\n",
      "\n",
      "adaptive huffman\n",
      "linux_1KB.txt:\n",
      "encoding:  0.321 [s]\n",
      "decoding:  0.296 [s]\n",
      "compresion rate: 20.525657071339168 %\n",
      "\n",
      "static huffman\n",
      "random_10kB.txt:\n",
      "encoding:  0.006 [s]\n",
      "decoding:  0.018 [s]\n",
      "compresion rate: -4.030000000000001 %\n",
      "\n",
      "adaptive huffman\n",
      "random_10kB.txt:\n",
      "encoding:  28.8668 [s]\n",
      "decoding:  28.6287 [s]\n",
      "compresion rate: 20.760000000000005 %\n",
      "\n",
      "static huffman\n",
      "linux_10KB.txt:\n",
      "encoding:  0.002 [s]\n",
      "decoding:  0.016 [s]\n",
      "compresion rate: 29.36986843406865 %\n",
      "\n",
      "adaptive huffman\n",
      "linux_10KB.txt:\n",
      "encoding:  5.4178 [s]\n",
      "decoding:  5.4602 [s]\n",
      "compresion rate: 31.605500049460872 %\n",
      "\n",
      "static huffman\n",
      "The_old_ones_100KB.txt:\n",
      "encoding:  0.022 [s]\n",
      "decoding:  0.131 [s]\n",
      "compresion rate: 43.52047523981107 %\n",
      "\n",
      "adaptive huffman\n",
      "The_old_ones_100KB.txt:\n",
      "encoding:  57.5675 [s]\n",
      "decoding:  56.5762 [s]\n",
      "compresion rate: 43.71427180211326 %\n",
      "\n",
      "static huffman\n",
      "Kritik_der_reinen_Vernunft_1MB.txt:\n",
      "encoding:  0.229 [s]\n",
      "decoding:  1.4586 [s]\n",
      "compresion rate: 46.399579992550144 %\n",
      "\n",
      "adaptive huffman\n",
      "Kritik_der_reinen_Vernunft_1MB.txt:\n",
      "encoding:  679.5731 [s]\n",
      "decoding:  732.7438 [s]\n",
      "compresion rate: 46.422359726213024 %\n",
      "\n",
      "static huffman\n",
      "random_1MB.txt:\n",
      "encoding:  0.2191 [s]\n",
      "decoding:  1.518 [s]\n",
      "compresion rate: 38.25 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(\"testy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
